### 线性回归
$$
\begin{align*}
f(x_i) = wx_i + b,
\end{align*}$$
属性离散情况：
- 属性间存在序的关系，转化为连续值
- 不存在序的关系，转化为k维向量
<!--ID: 1764664440152-->


#### 均方误差
$$\begin{array}{r}{E_{(w,b)}=\sum_{i=1}^{m}(y_{i}-w x_{i}-b)^{2}}\end{array}$$衡量f(x)与y之间的差别。
该函数关于w与b是凸函数，想要E最小，只需E关于w与b的导数为0即可。
$$ w = \frac{\displaystyle\sum_{i=1}^{m} y_i(x_i - \bar{x})}{\displaystyle\sum_{i=1}^{m} x_i^2 - \frac{1}{m} \left(\sum_{i=1}^{m} x_i\right)^2}
$$
$$
\begin{align*}
b = \frac{1}{m} \sum_{i=1}^m (y_i - w x_i)
\end{align*}$$
<!--ID: 1764664440155-->

#### 多元线性回归
$$
\begin{align*}
f(x_i) = w^T x_i + b, \text{ 使得 } f(x_i) \simeq y_i
\end{align*}
$$
样本有d个属性描述。
$$
\begin{align*}
\dot{\mathbf{w}}^* = \arg \min_{\mathbf{w}} \left( y - \mathbf{X} \dot{\mathbf{w}} \right)^T \left( y - \mathbf{X} \dot{\mathbf{w}} \right)
\end{align*}$$
$$
\begin{align*}
\frac{\partial E_{w}}{\partial \hat{w}} = 2 \, \mathbf{X}^{\mathrm{T}} ( \mathbf{X} \hat{w} - y )
\end{align*}$$
[[向量推导]]
$\mathbf{X}^{\mathrm{T}}  \mathbf{X}$为正定矩阵或满秩矩阵，则
$$
\begin{align*}
\hat{w}^* = \left( \mathbf{X}^{\mathrm{T}} \mathbf{X} \right)^{-1} \mathbf{X}^{\mathrm{T}} y
\end{align*}$$
$\mathbf{X}^{\mathrm{T}}  \mathbf{X}$不正定矩阵，如变量数超过样例数，导致 X 的列数多于行数。[[机器学习#^uoe65796of]]
<!--ID: 1764664440158-->


[[机器学习#^jfpn0ubdkrj|广义线性模型]]

### 对数几率回归
分类任务->回归任务
$$
\begin{align*}
\ln \frac{y}{1-y} = \boldsymbol{w}^{\mathrm{T}} \boldsymbol{x} + b \end{align*}$$
![[Pasted image 20251113185738.png]]
[[机器学习#^5iyx9qob63a|最优解]]
<!--ID: 1764664440161-->


### 线性判别分析LDA
![[Pasted image 20251113190201.png]]
<!--ID: 1764664440165-->


多分类学习
将多分类问题拆解为多个二分类任务求解。
OvO
OvR
MvM：纠错输出码

### 类别不平衡问题
分类任务中不同类别的训练样例数差别很大
- 欠采样
- 过采样
- 阈值偏移
<!--ID: 1764664440169-->

